---
title: "Serverless batched R scripts via Cloud Build"
date: "`r Sys.Date()`"
---

Cloud Build uses [Docker containers](https://www.docker.com/resources/what-container) to run everything.  This means it can run almost any language/program or application including R. Having an easy way to create and trigger these builds from R means R can serve as a UI or gateway to any other program e.g. R can trigger a Cloud Build using `gcloud` to deploy Cloud Run applications.

The first 120 mins per day are free.  [See here for more priceinfo.](https://cloud.google.com/cloud-build/pricing)

If you want to run scripts that can be triggered one time, batch style, and set them up to trigger on GitHub events or pub/sub, or schedule them using Cloud Scheduler then Cloud Build is suited to your use case. 

If you would also like to have your R code react in realtime to events such as HTTP or sub/sub events, such as a website or API endpoint, consider [Cloud Run](https://code.markedmondson.me/googleCloudRunner/articles/cloudrun.html). 

## The cloudbuild.yaml format

Cloud Build is centered around the [cloudbuild.yaml format](https://cloud.google.com/cloud-build/docs/build-config) - you can use existing cloudbuild.yaml files or create your own in R using the cloudbuild.yaml helper functions.

An example cloudbuild.yaml is shown below - this outputs the versions of docker and echos "Hello Cloud Build" and calls an R function:

```yaml
steps:
- name: 'gcr.io/cloud-builders/docker'
  id: Docker Version
  args: ["version"]
- name: 'alpine'
  id:  Hello Cloud Build
  args: ["echo", "Hello Cloud Build"]
- name: 'rocker/r-base'
  id: Hello R
  args: ["R", "-e", "paste0('1 + 1 = ', 1+1)"]

```

This cloudbuild.yaml file can be built directly via the `cr_build()` function.  The build will by default trigger a website URL to open with the build logs.  

```r
b1 <- cr_build("cloudbuild.yaml")
```

Or you can choose to wait in R for the build to finish, like below:

```r
b2 <- cr_build("cloudbuild.yaml", launch_browser = FALSE)
b3 <- cr_build_wait(b2)
# Waiting for build to finish:
#  |===||
# Build finished
# ==CloudBuildObject==
# buildId:  c673143a-794d-4c69-8ad4-e777d068c066 
# status:  SUCCESS 
# logUrl:  https://console.cloud.google.com/gcr/builds/c673143a-794d-4c69-8ad4-e777d068c066?project=1080525199262 
# ...
```

You can export an existing build into a cloudbuild.yaml file, for instance to run in another project not using R. 

```r
cr_build_write(b3, file = "cloudbuild.yml")
```

### Constructing Cloud Build objects

There are several layers to creating Cloud Build objects in R:

* `cr_build()` triggers the API with Cloud Build objects and cloudbuild.yaml files
* `cr_build_yaml()` lets you create the Cloud Build objects in R and can write to .yaml files.
* `cr_build_make()` creates Cloud Build R objects directly from .yaml files
* `cr_buildstep()` lets you create specific steps within the Cloud Build objects. There are helper template files with common tasks such as `cr_buildstep_r()`

For common use cases the `cr_deploy_*` functions use the above functions with some sensible defaults to quickly run use cases for you:

* `cr_deploy_docker()` - builds from a Dockerfile then pushes the Docker image to Google Container Registry
* `cr_deploy_docker_trigger()` - as above, plus creating a build trigger so the build will run upon each git commit - see the [Docker image use case](https://code.markedmondson.me/googleCloudRunner/articles/usecase-package-docker-build.html) for both.
* `cr_deploy_packagetests()` - create a build that will run R package unit tests and a build trigger to run them upon each commit - see the [package tests and code coverage use case](https://code.markedmondson.me/googleCloudRunner/articles/usecase-testthat-coverage.html)
* `cr_deploy_pkgdown()` - create a build that will deploy an R package website and a build trigger to create it upon each commit - see the [pkgdown website use case](https://code.markedmondson.me/googleCloudRunner/articles/usecase-deploy-pkgdown-website.html).
* ` cr_deploy_run_website()` - take HTML you have in a folder (perhaps created from an RMarkdown file) and deploy it to a nginx website on Cloud Run
* `cr_deploy_r()` - take the R script you supply and run it within a Cloud Build.  Optionally also schedule that R script - see the [R code on a schedule use case](https://code.markedmondson.me/googleCloudRunner/articles/usecase-scheduled-r-builds.html).
* `cr_deploy_run()` - takes a local folder, builds the Docker image suitable for Cloud run and deploys to Cloud Run.  Variants include `cr_deploy_plumber()` to R plumber APIs and `cr_deploy_html()` for nginx websites. See the [R micro-services](https://code.markedmondson.me/googleCloudRunner/articles/usecase-r-api-microservices.html), [trigger R functions from pub/sub](https://code.markedmondson.me/googleCloudRunner/articles/usecase-r-event-driven-pubsub.html) and [creating a Slackbot](https://code.markedmondson.me/googleCloudRunner/articles/usecase-slackbot-google-analytics.html) use cases

Some of the above are also available in an RStudio gadget.


### Docker images to use in Cloud Build

Any utility that has a Docker image can be used within Cloud Build steps.  

Official Google images for the `gcloud`, `bq` and `gsutil` are here: https://github.com/GoogleCloudPlatform/cloud-sdk-docker

Some [community contributed Cloud Build images are listed here](https://github.com/GoogleCloudPlatform/cloud-builders-community), including [hugo](https://github.com/GoogleCloudPlatform/cloud-builders-community/tree/master/hugo), [make](https://github.com/GoogleCloudPlatform/cloud-builders-community/tree/master/make), and [tar](https://github.com/GoogleCloudPlatform/cloud-builders-community/tree/master/tar), or you can configure your own Dockerfile and build what image you need yourself, perhaps by using a previous Cloud Build and `cr_deploy_docker()`

## Cloud Build source

Cloud Builds sometimes need code or data to work on to be useful.  

All cloudbuilds are launched in a serverless environment with a default directory `/workspace/`.  The Source is copied into this workspace before the build steps execute, so steps can share state and files. 
Cloud Build sources are specified by the `source` argument.

A source can be a [Cloud Source Repository](https://cloud.google.com/source-repositories/) (perhaps mirrored from GitHub) or a [Cloud Storage](https://cloud.google.com/storage/) bucket containing the code/data you want to operate on.  An example of specifying both is below:

```r
gcs_source <- cr_build_source(
  StorageSource("gs://my-bucket", "my_code.tar.gz"))
  
repo_source <- cr_build_source(
  RepoSource("github_markedmondson1234_googlecloudrunner",
             branchName="master"))

build1 <- cr_build("cloudbuild.yaml", source = gcs_source)
build2 <- cr_build("cloudbuild.yaml", source = repo_source)
```


`cr_build_upload_gcs()` is a helper function for automating creation of a Google Cloud Storage source  - this uses [`googleCloudStorageR`](http://code.markedmondson.me/googleCloudStorageR/)
 to tar and upload your source code locally to your bucket, making it available to your build.

This returns a `Source` object that can be used in build functions:

```r
storage <- cr_build_upload_gcs("my_folder")
cr_build(my_yaml, source = storage)
```

By default this will place your local folder's contents in the `/workspace/deploy/` folder.  For buildsteps to access those files you may want to add `dir="deploy"` to them so they will have their working directory start from there. 

## Cloud Build macros

Cloud Builds can use reserved macros and variables to help with deployments in a continuous development situation.  For instance, files can be named according to the Git branch they are committed from.  These are listed in `?Build` and reproduced below:

* $PROJECT_ID: the project ID of the build.
* $BUILD_ID: the autogenerated ID of the build.
* $REPO_NAME: the source repository name specified by RepoSource.
* $BRANCH_NAME: the branch name specified by RepoSource.
* $TAG_NAME: the tag name specified by RepoSource.
* $REVISION_ID or $COMMIT_SHA: the commit SHA specified by RepoSource or resolved from the specified branch or tag.
* $SHORT_SHA: first 7 characters of $REVISION_ID or $COMMIT_SHA.

Custom macros can also be configured, starting with _$ e.g. $_MY_CUSTOM_MACRO


## Creating cloudbuild.yml build steps 

Instead of using separate `cloudbuild.yml` files, you can also choose to make your own cloudbuild.yaml files in R via `cr_build_yaml()` and `cr_buildstep()`

Lets say you don't want to write a cloudbuild.yaml file manually - instead you can create all the features of the yaml files in R.  Refer to the [cloudbuild.yml config spec](https://cloud.google.com/cloud-build/docs/build-config) on what is expected in the files or functions. 

An example below recreates a simple cloudbuild.yml file.  If you print it to console it will output what the build would look like if it was in a yaml file:

```r
cr_build_yaml(steps = cr_buildstep( "gcloud","version"))
#==cloudRunnerYaml==
#steps:
#- name: gcr.io/cloud-builders/gcloud
#  args: version
```

You can write back out into your own cloudbuild.yml

```r
my_yaml <- cr_build_yaml(steps = cr_buildstep( "gcloud","version"))
cr_build_write(my_yaml, file = "cloudbuild.yaml")
```

And also edit or extract steps from existing cloudbuild.yml files via `cr_buildstep_edit()` and `cr_buildstep_extract()`.

This allows you to programmatically create cloudbuild yaml files for other languages and triggers.  See more at this article on [creating custom build steps with your own Docker images](https://cloud.google.com/cloud-build/docs/create-custom-build-steps).

## Pre-made Build Step templates

Using the above build step editing functions, some helpful build steps you can use in your own cloudbuild steps have been included in the package.

* `cr_buildstep_gcloud()` - an optimised docker for `gcloud`, `bq`, `gsutil` or `kubectl` commands
* `cr_buildstep_bash()` - for including bash scripts
* `cr_buildstep_docker()` - for building and pushing Docker images
* `cr_buildstep_secret()` - storing secrets in the cloud and decrypting them
* `cr_buildstep_decrypt()` - for using Google Key management store to decrypt auth files
* `cr_buildstep_git()` - for setting up and running git commands
* `cr_buildstep_mailgun()` - send an email with Mailgun.org
* `cr_buildstep_nginx_setup()` -  setup hosting HTML files with nginx on Cloud Run
* `cr_buildstep_pkgdown()` - for setting up pkgdown documentation of an R package
* `cr_buildstep_r()` - for running R code
* `cr_buildstep_slack()` - send a Slack webhook message

If you have any requests for others, please [raise an issue on GitHub](https://github.com/MarkEdmondson1234/googleCloudRunner/issues). 

Combine buildsteps with `c()` e.g.

```r
cr_build_yaml(
      steps = c(
        cr_buildstep("ubuntu", "echo hello"),
        cr_buildstep_gcloud("gcloud","version"),
        cr_buildstep_docker("my-image", tag="dev"),
        cr_buildstep_secret("my_secret","auth.json"),
        cr_buildstep_r("sessionInfo()")),
      images = "gcr.io/my-project/my-image")
```

The `cr_buildstep_*` functions are all calling `cr_buildstep()` with helpful defaults, for example these are equivalent:

```r
cr_buildstep_bash("echo hello world")
#[[1]]
#==cloudRunnerBuildStep==
#name: ubuntu
#args:
#- bash
#- -c
#- echo hello world
cr_buildstep("ubuntu", args = c("bash", "-c", "echo hello world"), prefix = "")
#[[1]]
#==cloudRunnerBuildStep==
#name: ubuntu
#args:
#- bash
#- -c
#- echo hello world
```

## Build Artifacts

You may have some useful files or data after your buildsteps that you want to use later.  You can specify these files as **artifacts** that will be uploaded to a Google Cloud Storage bucket after the build finishes.  A helper function `cr_build_artifacts()` will take your build object and download the files to your local directory via `googleCloudStorageR`


```r
r <- "write.csv(mtcars,file = 'artifact.csv')"
ba <- cr_build_yaml(
     steps = cr_buildstep_r(r),
     artifacts = cr_build_yaml_artifact('artifact.csv')
     )

build <- cr_build(ba)
built <- cr_build_wait(build)

cr_build_artifacts(built)
# 2019-12-22 12:36:10 -- Saved artifact.csv to artifact.csv (1.7 Kb)

read.csv("artifact.csv")
#                     X  mpg cyl  disp  hp drat    wt  qsec vs am gear carb
#1            Mazda RX4 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
#2        Mazda RX4 Wag 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
#3           Datsun 710 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
#4       Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
# ... etc ...
```

## Build Logs

You can view the logs of the build locally in R using `cr_build_logs()`

Pass in the built logs via `cr_build_wait()` or `cr_build_status()`

```r
s_yaml <- cr_build_yaml(steps = cr_buildstep( "gcloud","version"))
build <- cr_build_make(s_yaml)

built <- cr_build(build)

the_build <- cr_build_wait(built)

cr_build_logs(the_build)
# [1] "starting build \"6ce86e05-b0b1-4070-a849-05ec9020fd3b\""       
# [2] ""                                                              
# [3] "FETCHSOURCE"                                                   
# [4] "BUILD"                                                         
# [5] "Already have image (with digest): gcr.io/cloud-builders/gcloud"
# [6] "Google Cloud SDK 325.0.0"                                      
# [7] "alpha 2021.01.22"                                              
# [8] "app-engine-go 1.9.71"        
# ...
```

### RStudio Gadget - build Docker

If you are using RStudio, installing the library will enable an [RStudio Addin](https://rstudio.github.io/rstudioaddins/) that can be called after you have setup the library as per the setup page. 

It includes a Shiny gadget that you can call via the Addin menu in RStudio, via `googleCloudRunner::cr_deploy_gadget()` or assigned to a hotkey (I use CTRL+SHIFT+D).

This sets up a Shiny UI to help smooth out deployments as pictured:

![](gadget_docker.png)


## R buildsteps

Focusing on one buildstep in particular, since this is an R package - you can send in R code into a build trigger using `cr_buildstep_r()`.   

It accepts both inline R code or a file location.  This R code is executed in the R environment as specified in argument `name` - they default to the R images provided by Rocker [rocker-project.org](https://www.rocker-project.org/).  

If you want to build your own images (in perhaps another Cloud Build using `cr_deploy_docker()`) you can use your own R images with custom R packages and resources. 

Some useful R images have been made you could use or refer to their Dockerfiles for:

* `gcr.io/gcer-public/packagetools` - installs: devtools covr rhub pkgdown goodpractice httr plumber rmarkdown
* `gcr.io/gcer-public/render_rmd` - installs: pkgdown rmarkdown flexdashboard blogdown bookdown
* `gcr.io/gcer-public/googlecloudrunner` - installs: containerit, googleCloudStorageR, plumber, googleCloudRunner

The R code can be created within the Build at build time, or you can refer to an existing R script within the Source.

```r
# create an R buildstep inline
cr_buildstep_r(c("paste('1+1=', 1+1)", "sessionInfo()"))

# create an R buildstep from a local file
cr_buildstep_r("my-r-file.R")

# create an R buildstep from a file within the source of the Build
cr_buildstep_r("inst/schedule/schedule.R", r_source = "runtime")

# use a different Rocker image e.g. rocker/verse
cr_buildstep_r(c("library(dplyr)", "mtcars %>% select(mpg)", "sessionInfo"),
                name = "verse")

# use your own R image with custom R
my_r <- c("devtools::install()", "pkgdown::build_site()")
br <-  cr_buildstep_r(my_r, name= "gcr.io/gcer-public/packagetools:latest")

# send it for building
cr_build(cr_build_yaml(steps=br))

```

## Build Triggers

Once you have build steps and possibly a source created, you can either set these up to run on a schedule via `cr_schedule()` or you can use triggers that will run upon certain events.  

### Setting up Build Triggers in the Web UI

The quickest way to get going is to use the web UI for Build Triggers (`https://console.cloud.google.com/cloud-build/triggers`)

1. Link your repo (GitHub, Bitbucket or Cloud Repositories) to Google 
2. Create your Cloud Build using `cr_build_yaml()` etc.
3. Write out to a `cloudbuild.yml` file in your repository (by default the root directory is checked)
4. Setup the Build Trigger in the Web UI (`https://console.cloud.google.com/cloud-build/triggers`)
5. Make a git commit and check the Cloud Build has run in the history (`https://console.cloud.google.com/cloud-build/builds`)
6. Modify the `cloudbuild.yml` file as you need, recommit to trigger a new build. 

Learn how to set them up at this Google article on [creating and managing build triggers](https://cloud.google.com/cloud-build/docs/running-builds/create-manage-triggers).

From there you get the option of connecting a repository either by mirroring it from GitHub/Bitbucket or using Cloud Source Repositories.

You can setup either Docker builds by just providing the location of the `Dockerfile`, or have more control by providing a `cloudbuild.yml` - by default these are looked for in the root directory.

Here are some example for this package's GitHub repo:

![](buildtrigger_screen.png)

* The "do package checks" performs authenticated tests against the package
* The "git auth and push pkgdown website" rebuilds the website each commit to master branch.
* "Build a dockerfile for package builds" builds the `gcr.io/gcer-public/packagetools` image
* "pushGoogleCloudRunnerToGcerPublic" builds the `gcr.io/gcer-public/googlecloudrunner` image

![](buildtrigger_example.png)


### Build Triggers via code

Build Triggers can be made via R code using the `cr_buildtrigger()` function.   

Build Triggers include GitHub commits and pull requests.

The example below shows how to set up some of the builds above:

```r
cloudbuild <- system.file("cloudbuild/cloudbuild.yaml",
                            package = "googleCloudRunner")
bb <- cr_build_make(cloudbuild, projectId = "test-project")
github <- cr_buildtrigger_repo("MarkEdmondson1234/googleCloudRunner", branch = "master")

cr_buildtrigger(bb, name = "trig1", trigger = github)
```

The Build macros can also be configured by passing in a named list:

```r
# creates a trigger with named substitutions
ss <- list(`$_MYVAR` = "TEST1", `$_GITHUB` = "MarkEdmondson1234/googleCloudRunner")
cr_buildtrigger("trig2", trigger = github, build = bb, substitutions = ss)
```

The above examples will create the build step inline within the trigger, but you can also use existing cloudbuild.yaml files by specifying where in the repository the build file will be:

```r
# create a trigger that will build from the file in the repo
cr_buildtrigger("cloudbuild.yaml", name = "trig3", trigger = github)
```

This way you can commit changes to the cloudbuild.yaml file, and they will be reflected in the Build Trigger. 

### Connecting to GitHub 

You can connect via the [Source Repository mirroring service](https://cloud.google.com/source-repositories/docs/mirroring-a-github-repository) or via the [Google Cloud Build GitHub app](https://github.com/marketplace/google-cloud-build) - see the [git setup page](https://code.markedmondson.me/googleCloudRunner/articles/git.html) for more details.

### Combining buildsteps from triggers with other builds

It may be you want to combine build steps from across buildtriggers.  For example, you have a Docker build triggers and want to add some steps that use that Docker image after its been built.

You can extract the buildsteps from deployed buildtriggers to combine them and avoid having two builds.

For example, say you have deployed a Dockerfile trigger:

```r
repo <- cr_buildtrigger_repo("your-github/your-repo")

# first time - by default will be called "docker-{image}"
cr_deploy_docker_trigger(repo, image = "my-build")
```

If you want to extract the docker buildsteps you can find it in `dock_build$build$steps` below:

```r
# get the buildtrigger details
dock_build <- cr_buildtrigger_get("docker-my-build")

# contains the buildsteps from the deployment
dock_build$build$steps
```

You can then combine those buildsteps in the usual way with other buildsteps.  The example below assumes you've made an R docker image with some of your custom dependencies that you then want to immediately run your R code within:

```r
# uses the docker image previously created
my_r_step <- cr_buildstep_r(r = "my_r_code.R", name = "docker-my-build")

# combine the buildsteps
new_buildsteps <- c(dock_build$build$steps, my_r_step)

# remake the build yaml
yml <- cr_build_yaml(new_buildsteps)
```

You can then reconfigure the build trigger with your new build yaml.  The below writes the yaml to a file to be read by the build trigger:

```r
# write it out to the git repo we are in
cr_build_write(yml, "new_buildsteps.yml")

repo <- cr_buildtrigger_repo("your-github/your-repo")

# overwrite the deployed build trigger to read the yml
cr_buildtrigger(
  "new_buildsteps.yml",
  name = "docker-my-build",
  trigger = repo,
  overwrite = TRUE
)
```

