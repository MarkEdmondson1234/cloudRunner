#' Deploy an R script with an optional schedule
#'
#' Will create a build to run an R script in Cloud Build with an optional schedule from Cloud Scheduler
#'
#' @inheritParams cr_buildstep_r
#' @inheritParams cr_build
#' @inheritParams cr_schedule
#' @inheritParams cr_build_schedule_http
#' @param r_image The R docker environment exectuting the R code
#' @param run_name What name the R code will identify itself as.  If \code{NULL} one is autogenerated.
#' @param pre_steps Other \link{cr_buildstep} to run before the R code executes
#' @param post_steps Other \link{cr_buildstep} to run after the R code executes
#' @details
#'
#' If \code{schedule=NULL} then the R script will be run immediatly on Cloud Build via \link{cr_build}.
#'
#' If \code{schedule} carries a cron job string (e.g. \code{"15 5 * * *"}) then the build will be scheduled via Cloud Scheduler to run as described in \link{cr_build_schedule_http}
#'
#' The R script will execute within the root directory of which \link{Source} you supply, usually created via \link{cr_build_source}.  Bear in mind if the source changes then the code scheduled may need updating.
#'
#' The \code{r_image} dictates what R libraries the R environment executing the code of \code{r} will have, via the underlying Docker container usually supplied by rocker-project.org.  If you want custom R libraries beyond the default, create a docker container with those R libraries installed (perhaps via \link{cr_deploy_docker})
#'
#' @return If scheduling then a \link{Job}, if building immediately then a \link{Build}
#' @family Deployment functions
#' @export
#'
#' @seealso If you want to run R code upon certain events like GitHub pushes, look at \link{cr_buildtrigger}
#'
#' @examples
#'
#' r_lines <- c("list.files()",
#'              "library(dplyr)",
#'              "mtcars %>% select(mpg)",
#'              "sessionInfo()")
#' source <- cr_build_source(RepoSource("googleCloudStorageR",
#'                                      branchName = "master"))
#'
#' \dontrun{
#' # check the script runs ok
#' cr_deploy_r(r_lines, source = source)
#'
#' # schedule the script
#' cr_deploy_r(r_lines, schedule = "15 21 * * *", source = source)
#' }
#'
cr_deploy_r <- function(r,
                        schedule = NULL,
                        source = NULL,
                        run_name = NULL,
                        r_image = "rocker/verse",
                        pre_steps = NULL,
                        post_steps = NULL,
                        timeout = 600L,
                        email = cr_email_get(),
                        region = cr_region_get(),
                        projectId = cr_project_get(),
                        launch_browser=interactive()){

  if(is.null(run_name)){
    run_name <- paste0("cr_rscript_", format(Sys.time(), "%Y%m%s%H%M%S"))
  }

  myMessage(paste("Deploy R script ",run_name," to Cloud Build"), level = 3)

  build <- cr_build_yaml(
    steps = c(pre_steps,
              cr_buildstep_r(r = r,
                             name = r_image,
                             id = run_name),
              post_steps)
  )

  br <- cr_build_make(build,
                      source = source,
                      timeout = timeout,
                      projectId = projectId)

  if(!is.null(schedule)){
    # a cloud build you would like to schedule
    myMessage(paste0("Scheduling R script on cron schedule:", schedule),
              level = 3)

    https <- cr_build_schedule_http(br,
                                   email = email,
                                   projectId = projectId)

    brs <- cr_schedule(schedule,
                       name=run_name,
                       region = region,
                       description = run_name,
                       httpTarget = https)
    return(brs)
  }

  # build it now
  br1 <- cr_build(br, launch_browser=launch_browser)

  cr_build_wait(br1, projectId = projectId)

}


#' Deploy an R plumber script to Cloud Run
#'
#' Helper to take an R plumber script, create the Dockerfile, add the build to Cloud Build and deploy to Cloud Run
#'
#' @param local A folder containing the R script using plumber called api.R and all its dependencies
#' @param remote The folder on Google Cloud Storage, and the name of the service on Cloud Run
#' @param dockerfile An optional Dockerfile built to support the script.  Not needed if 'Dockerfile' exists in folder.  If supplied will be copied into deployment folder and called "Dockerfile"
#' @param image_name The gcr.io image name that will be deployed and/or built
#' @param projectId The projectId where it all gets deployed to
#' @param region The Cloud Run endpoint set by CR_REGION env arg
#' @param bucket The Cloud Storage bucket that will hold the code
#' @inheritParams cr_buildstep_docker
#' @inheritParams cr_build
#' @family Deployment functions
#' @details
#'
#' The entrypoint for CloudRun will be via a plumber script called api.R - this should be included in your local folder to deploy.
#' From that api.R you can source or call other resources in the same folder, using relative paths.
#'
#' The function will create a local folder called "deploy" and a tar.gz of that folder which is what is being uploaded to Google Cloud Storage
#'
#' It will call \link{cr_deploy_docker} to create the image to deploy on Cloud Run
#'
#' @export
#' @examples
#'
#' \dontrun{
#'
#' cr_deploy_run(system.file("example/", package = "googleCloudRunner"))
#'
#' }
cr_deploy_run <- function(local,
                          remote = basename(local),
                          dockerfile = NULL,
                          image_name = remote,
                          tag = "$BUILD_ID",
                          region = cr_region_get(),
                          bucket = cr_bucket_get(),
                          projectId = cr_project_get(),
                          launch_browser = interactive(),
                          timeout=600L){

  myMessage("Uploading ", local, " folder for Cloud Run", level = 3)
  local_files <- list.files(local)
  if(!"api.R" %in% local_files){
    stop("Must include api.R in local deployment folder
         with library(plumber) implementation
         for Cloud Run deployments", call. = FALSE)
  }

  image_name <- make_image_name(image_name, projectId)

  task_id <- rstudio_add_job(
    paste("Deploy service ",remote," to CloudRun"),
    timeout=extract_timeout(timeout))

  built <- cr_deploy_docker(local,
                      image_name = image_name,
                      dockerfile = dockerfile,
                      remote = remote,
                      tag = tag,
                      bucket = bucket,
                      projectId = projectId,
                      launch_browser = launch_browser,
                      timeout=timeout,
                      task_id=task_id)
  if(built$status != "SUCCESS"){
    myMessage("Error building Dockerfile", level = 3)
    rstudio_add_state(task_id, "FAILURE")
    return(built)
  }

  cr_run(built$results$images$name,
         name = tolower(remote),
         region = region,
         projectId = projectId,
         launch_browser=launch_browser,
         timeout=timeout,
         task_id=task_id)

}

make_image_name <- function(name, projectId){
  prefix <- grepl("^gcr.io", name)
  if(prefix){
    the_image <- name
  } else {
    the_image <- sprintf("gcr.io/%s/%s", projectId, name)
  }
  tolower(the_image)
}

#' Deploy a Dockerfile to be built on ContainerRegistry
#'
#' If no Dockerfile present in the deployment folder, will attempt to create a Dockerfile to upload via \link{cr_dockerfile}
#'
#' @param local The folder containing the Dockerfile to build
#' @param remote The folder on Google Cloud Storage
#' @param dockerfile An optional Dockerfile built to support the script.  Not needed if 'Dockerfile' exists in folder.  If supplied will be copied into deployment folder and called "Dockerfile"
#' @param bucket The GCS bucker that will be used to deploy code source
#' @param image_name The name of the docker image to be built either full name starting with gcr.io or constructed from the image_name and projectId via \code{gcr.io/{projectId}/{image_name}}
#' @param task_id RStudio job task_id if you want to use the same task
#' @inheritParams cr_buildstep_docker
#' @inheritParams cr_build
#' @export
#' @family Deployment functions
#' @examples
#'
#' \dontrun{
#'
#' cr_deploy_docker(system.file("example/", package="googleCloudRunner"))
#'
#' }
cr_deploy_docker <- function(local,
                             image_name = remote,
                             dockerfile = NULL,
                             remote = basename(local),
                             tag = "$BUILD_ID",
                             timeout = 600L,
                             bucket = cr_bucket_get(),
                             projectId = cr_project_get(),
                             launch_browser = interactive(),
                             task_id=NULL){
  assert_that(
    dir.exists(local)
  )

  myMessage("Building ", local, " folder for Docker image: ", image_name, level = 3)

  this_job <- FALSE
  if(is.null(task_id)){
    this_job <- TRUE
    task_id <- rstudio_add_job("Deploy Docker",
                               timeout=extract_timeout(timeout))
  }

  rstudio_add_output(task_id, paste("\nConfiguring Dockerfile"))
  use_or_create_dockerfile(local, dockerfile = dockerfile)

  assert_that(
    is.readable(file.path(local, "Dockerfile"))
  )

  image <- make_image_name(image_name, projectId = projectId)

  build_yaml <- cr_build_yaml(
    steps = cr_buildstep_docker(image,
                                tag = tag,
                                location = ".",
                                dir=paste0("deploy/", remote),
                                projectId = projectId),
    images = image)

  image_tag <- paste0(image, ":", tag)
  rstudio_add_output(task_id,
    paste("\n#Deploy docker build for image: \n", image_tag))

  gcs_source <- cr_build_upload_gcs(local,
                                    remote = remote,
                                    bucket = bucket,
                                    task_id=task_id)

  docker_build <- cr_build(build_yaml,
                           source = gcs_source,
                           launch_browser = launch_browser,
                           timeout=timeout)

  b <- cr_build_wait(docker_build,
                     projectId = projectId,
                     task_id=task_id)

  rstudio_add_output(task_id, image_tag)

  b
}

#' Deploy Docker build from a GitHub repo
#'
#' This helps the common use case of building a Dockerfile based on the contents of a GitHub repo, and sets up a build trigger so it will build on every commit.
#'
#' @seealso \link{cr_deploy_docker} which lets you build Dockerfiles for more generic use cases
#'
#' @param x The GitHub repo e.g. \code{MarkEdmondson1234/googleCloudRunner}
#' @param image The name of the image you want to build
#' @param branch A regex of the GitHub branches that will trigger a build
#' @param image_tag What to tag the build docker image
#' @param dockerfile_location Where the Dockerfile sits within the GitHub repo
#' @param github_tag Regexes matching what tags to build. If not NULL then argument branch will be ignored
#' @param projectId The project to build under
#' @param timeout timeout for the Docker build
#' @family Deployment functions
#' @export
cr_deploy_docker_github <- function(x,
                                    image = x,
                                    branch = ".*",
                                    image_tag = "$SHORT_SHA",
                                    dockerfile_location = ".",
                                    github_tag = NULL,
                                    timeout = 600L,
                                    projectId = cr_project_get()){

  build_docker <- cr_build_make(
    cr_build_yaml(
      steps = cr_buildstep_docker(image,
                                  tag = image_tag,
                                  location = dockerfile_location),
      images = paste0("gcr.io/", projectId, "/", "image"),
      timeout = timeout
      ))

  github <- GitHubEventsConfig(x, branch = branch, tag = github_tag)

  safe_name <- gsub("[^a-zA-Z1-9]","-", x)
  cr_buildtrigger(safe_name,
                  description = safe_name,
                  trigger = github,
                  build = build_docker)
}

#' Deploy a trigger for auto-builds a pkgdown website for an R package
#'
#' This will build a pkgdown website each time the trigger fires and deploy it to git
#'
#' @inheritParams cr_buildstep_pkgdown
#' @inheritParams cr_buildtrigger
#' @param steps extra steps to run before the pkgdown website steps run
#' @param substitutions A named list of Custom Build macros that can be substituted for values in the build steps.  Will be added to an existing default substitution \code{_$GIT_REPO} which holds the git repo as deployed in \code{trigger}
#'
#' @details
#'
#' The trigger repository needs to hold an R package configured to build a pkgdown website.
#'
#' For GitHub, the repository will also need to be linked to the project you are building within, via \url{https://console.cloud.google.com/cloud-build/triggers/connect}
#'
#' The git ssh keys need to be deployed to Google KMS for the deployment of the website - see \link{cr_buildstep_git} - this only needs to be done once per Git account.  You then need to commit the encrypted ssh key (by default called \code{id_rsa.enc})
#'
#' @seealso Create your own custom deployment using \link{cr_buildstep_pkgdown} which this function uses with some defaults
#' @family Deployment functions
#' @export
#' @examples
#'
#' \dontrun{
#'
#' my_repo <- GitHubEventsConfig("MarkEdmondson1234/googleAnalyticsR")
#' cr_deploy_pkgdown(my_repo)
#'
#' }
cr_deploy_pkgdown <- function(trigger,
                              steps = NULL,
                              git_email = "googlecloudrunner@r.com",
                              keyring = "my-keyring",
                              key = "github-key",
                              env = NULL,
                              substitutions = NULL,
                              cipher = "id_rsa.enc",
                              build_image = 'gcr.io/gcer-public/packagetools:master'){

  github_repo <- extract_repo(trigger)

  build_yaml <-
    cr_build_yaml(steps = c(steps,
                   cr_buildstep_pkgdown("$_GIT_REPO",
                                      git_email = git_email,
                                      env = env))
         )

  build <- cr_build_make(build_yaml)

  pkgdown_name <- paste0("pkgdown-deploy-", tolower(basename(github_repo)))
  trigger <- cr_buildtrigger(pkgdown_name,
                             trigger = trigger,
                             build = build,
                             description = pkgdown_name,
                             substitutions = c(list(`_GIT_REPO` = github_repo),
                                               substitutions))
  myMessage(paste("pkgdown trigger deployed for repo:", github_repo,
                  "- ensure git ssh key is on KMS and ", cipher,
                  "is checked into the repository - after which the website will be built on each commit"),
            level = 3)
  trigger

}

extract_repo <- function(x){
  if(is.gar_RepoSource(x)){
    return(x$repoName)
  } else if(is.gar_GitHubEventsConfig(x)){
    return(paste0(x$owner,"/",x$name))
  } else {
    stop("Could not find repo from object of class ", class(x), call. = FALSE)
  }
}
