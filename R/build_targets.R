#' @title Set up Google Cloud Build to run a targets pipeline
#' @export
#' @family Cloud Build functions
#' @description Creates a Google Cloud Build yaml file so as to execute \link[targets]{tar_make} pipelines
#'
#' Historical runs accumulate in the
#'   configured Google Cloud Storage bucket, and the latest output is downloaded before
#'   \link[targets]{tar_make} executes so up-to-date steps do not rerun.
#' @details Steps to set up your target task in Cloud Build:
#'
#' \itemize{
#'   \item Create your `targets` workflow.
#'   \item Create a Dockerfile that holds the R and system dependencies for your workflow.  You can test the image using \link{cr_deploy_docker()}.  Include \code{library(targets)} dependencies - a Docker image with \code{targets} installed is available at \code{gcr.io/gcer-public/targets}.
#'   \item Run \code{cr_build_targets()} to create the cloudbuild yaml file.
#'   \item Run the build via \link{cr_build} or similar.  Each build should only recompute outdated targets.
#'   \item Optionally create a build trigger via \link{cr_buildtrigger}.
#'   \item Trigger a build. The first trigger will run the targets pipeline, subsequent runs will only recompute the outdated targets.
#'  }
#'
#' @return A Yaml object as generated by \link{cr_build_yaml}
#' @param path File path to write the Google Cloud Build yaml workflow file. Set to NULL to write no file and just return the \link{Yaml} object.
#' @param task_image An existing Docker image that will be used to run your targets workflow after the targets meta has been downloaded from Google Cloud Storage
#' @param target_folder Where target metadata will sit within the Google Cloud Storage bucket as a folder.  Defaults to RStudio project name.
#' @param bucket The Google Cloud Storage bucket the target metadata will be saved to in folder `target_folder`
#' @param ... Other arguments passed to \link{cr_build_yaml()}
#' @inheritDotParams cr_build_yaml
#' @param task_args A named list of additional arguments to send to \link{cr_buildstep_r()} when its executing the \link[targets]{tar_make()} command (such as environment arguments)
#' @param tar_make The R script that will run in the tar_make() step. Modify to include custom settings such as "script"
#'
#' @examples
#'
#' cr_build_targets(path=tempfile())
#'
#' # adding custom environment args and secrets to the build
#' cr_build_targets(
#'   task_image = "gcr.io/my-project/my-targets-pipeline",
#'   options = list(env = c("ENV1=1234",
#'                          "ENV_USER=Dave")),
#'   availableSecrets = cr_build_yaml_secrets("MY_PW","my-pw"),
#'   task_args = list(secretEnv = "MY_PW"))
#'
cr_build_targets <- function(
  task_image = "gcr.io/gcer-public/targets",
  target_folder = basename(rstudioapi::getActiveProject()),
  path = "cloudbuild_targets.yaml",
  bucket = cr_bucket_get(),
  task_args = list(),
  tar_make = "targets::tar_make()",
  ...
) {

  if(is.null(target_folder)){
    target_folder <- "targets_cloudbuild"
  }

  myMessage(sprintf("targets cloud location: gs://%s/%s", bucket, target_folder),
            level = 3)

  bs <- c(
    cr_buildstep_bash(
      "mkdir /workspace/_targets && mkdir /workspace/_targets/meta && gsutil -m cp -r ${_TARGET_BUCKET}/_targets/meta /workspace/_targets || exit 0",
      name = "gcr.io/google.com/cloudsdktool/cloud-sdk:alpine",
      entrypoint = "bash",
      escape_dollar = FALSE,
      id = "get previous _targets metadata"
    ),
    do.call(
      cr_buildstep_r,
      args = c(task_args,
               list(r =tar_make,
                    name = task_image,
                    id = "target pipeline"))
    ),
    cr_buildstep_bash(
      "date > buildtime.txt && gsutil cp buildtime.txt ${_TARGET_BUCKET}/_targets/buildtime.txt",
      name = "gcr.io/google.com/cloudsdktool/cloud-sdk:alpine",
      entrypoint = "bash",
      escape_dollar = FALSE,
      id = "Ensure ${_TARGET_BUCKET}/_targets/ always exists"
    ),
    cr_buildstep_gcloud(
      "gsutil",
      args = c("-m", "cp" ,"-r", "/workspace/_targets" ,"${_TARGET_BUCKET}"),
      id = "Upload Artifacts this way as artifacts doesn't support folders"
      ),
    cr_buildstep_gcloud(
      "gsutil",
      args = c("ls", "-r","${_TARGET_BUCKET}"),
      id = "Artifacts location"
    )
  )

  # gs://bucket-name/target-folder
  target_bucket <- sprintf("gs://%s/%s", bucket, target_folder)

  yaml <- cr_build_yaml(
    bs,
    substitutions = list(`_TARGET_BUCKET` = target_bucket),
    timeout = 3600,
    ...
  )

  if(!is.null(path)) cr_build_write(yaml, file = path)

  yaml
}

#' @rdname cr_build_targets
#' @export
#' @details
#'   Use \code{cr_build_targets_artifacts} to download the return values of a
#'   target Cloud Build, then \link[targets]{tar_read} to read the results.  You can set the downloaded files as the target store via \code{targets::tar_config_set(store="_targets_cloudbuild")}.  Set \code{download_folder = "_targets"} to overwrite your local targets store.
#' @inheritParams cr_build_artifacts
#' @param target_subfolder If you only want to download a specific folder from the _targets/ folder on Cloud Build then specify it here.
#' @return \code{cr_build_targets_artifacts} returns the file path to where the download occurred.
cr_build_targets_artifacts <- function(
  build,
  download_folder = "_targets_cloudbuild",
  target_subfolder = c("all","meta","objects","user"),
  overwrite = TRUE){

  target_subfolder <- match.arg(target_subfolder)

  bb <- build$source$storageSource$bucket
  if(is.null(bb)){
    stop("Could not find bucket.  Is this not a build from cr_build_targets()?")
  }

  build_folder <- build$substitutions$`_TARGET_BUCKET`
  build_folder <- gsub(paste0("gs://",bb,"/"),"",build$substitutions$`_TARGET_BUCKET`)

  if(!nzchar(build_folder)){
    stop("Could not find build folder in bucket.")
  }

  prefix <- build_folder
  if(target_subfolder != "all"){
    prefix <- paste0(prefix, "/", target_subfolder)
  }

  arts <- googleCloudStorageR::gcs_list_objects(
    bucket = bb, prefix = prefix
  )

  if(nrow(arts) == 0){
    myMessage("No target build artifacts found")
    return(NULL)
  }

  # create targets folder structure
  dir.create(download_folder, showWarnings = FALSE)
  dir.create(file.path(download_folder, build_folder), showWarnings = FALSE)
  dir.create(file.path(download_folder, build_folder, "_targets"),
             showWarnings = FALSE)
  dir.create(file.path(download_folder, build_folder, "_targets","meta"),
             showWarnings = FALSE)
  dir.create(file.path(download_folder, build_folder, "_targets","objects"),
             showWarnings = FALSE)
  dir.create(file.path(download_folder, build_folder, "_targets","user"),
             showWarnings = FALSE)

  withr::with_dir(
    download_folder,
    {
      lapply(arts$name, function(x) {
        gcs_get_object(x,
                       bucket = bb,
                       saveToDisk = x,
                       overwrite = overwrite)
      })
    }
  )

  normalizePath(file.path(download_folder, build_folder))

}
